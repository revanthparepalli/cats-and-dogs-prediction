{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Building CNN for cat and dog classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialising the CNN\n",
    "- Convolution  \n",
    "- Pooling  \n",
    "- Flattening  \n",
    "- Full connection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-07 05:45:27.036939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-07 05:45:27.036978: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-07 05:45:27.037013: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LMS-Prod-VM): /proc/driver/nvidia/version does not exist\n",
      "2021-08-07 05:45:27.037243: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modell compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Image augmentation & Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-revanthparepalli/.conda/envs/pyrevanth3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-08-07 05:46:18.039858: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-07 05:46:18.040490: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2294680000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.6915 - accuracy: 0.6081 - val_loss: 0.6428 - val_accuracy: 0.6400\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.5947 - accuracy: 0.6831 - val_loss: 0.5852 - val_accuracy: 0.6890\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.5570 - accuracy: 0.7150 - val_loss: 0.5388 - val_accuracy: 0.7320\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 41s 165ms/step - loss: 0.5424 - accuracy: 0.7266 - val_loss: 0.5439 - val_accuracy: 0.7320\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.5281 - accuracy: 0.7352 - val_loss: 0.5392 - val_accuracy: 0.7335\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 42s 170ms/step - loss: 0.5097 - accuracy: 0.7495 - val_loss: 0.5178 - val_accuracy: 0.7480\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.4965 - accuracy: 0.7560 - val_loss: 0.5496 - val_accuracy: 0.7350\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.4799 - accuracy: 0.7619 - val_loss: 0.5874 - val_accuracy: 0.7055\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 41s 166ms/step - loss: 0.4734 - accuracy: 0.7732 - val_loss: 0.5353 - val_accuracy: 0.7540\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.4560 - accuracy: 0.7794 - val_loss: 0.5238 - val_accuracy: 0.7720\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.4466 - accuracy: 0.7878 - val_loss: 0.5401 - val_accuracy: 0.7735\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.4347 - accuracy: 0.7885 - val_loss: 0.5803 - val_accuracy: 0.7315\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.4294 - accuracy: 0.7952 - val_loss: 0.5241 - val_accuracy: 0.7670\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.4125 - accuracy: 0.8059 - val_loss: 0.5472 - val_accuracy: 0.7675\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.4065 - accuracy: 0.8110 - val_loss: 0.5598 - val_accuracy: 0.7500\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.3904 - accuracy: 0.8235 - val_loss: 0.5406 - val_accuracy: 0.7630\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 41s 166ms/step - loss: 0.3890 - accuracy: 0.8235 - val_loss: 0.5268 - val_accuracy: 0.7825\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.3711 - accuracy: 0.8295 - val_loss: 0.5313 - val_accuracy: 0.7760\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.3633 - accuracy: 0.8388 - val_loss: 0.5507 - val_accuracy: 0.7660\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.3563 - accuracy: 0.8401 - val_loss: 0.5556 - val_accuracy: 0.7755\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.3471 - accuracy: 0.8461 - val_loss: 0.5558 - val_accuracy: 0.7660\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.3304 - accuracy: 0.8529 - val_loss: 0.5821 - val_accuracy: 0.7590\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.3282 - accuracy: 0.8549 - val_loss: 0.5684 - val_accuracy: 0.7705\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 41s 165ms/step - loss: 0.3188 - accuracy: 0.8615 - val_loss: 0.6253 - val_accuracy: 0.7540\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.3072 - accuracy: 0.8677 - val_loss: 0.6648 - val_accuracy: 0.7535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99d0aa2c10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create an object of ImageDataGenerator, for augmenting train set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "##create another object of ImageDataGenerator, for augmenting test set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "##apply image augmentation on train set by resizing all images to 64x64 and creating batches of 32 images.\n",
    "training_set = train_datagen.flow_from_directory('training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "##apply image augmentation on test set by resizing all images to 64x64 and creating batches of 32 images.\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "\n",
    "###steps_per_epoch: num of data divided by batch size\n",
    "###validation_steps: num of data divided by batch size\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = (8000/32),\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = (2000/32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_from_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_386/2531571173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloaded_model_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_from_json' is not defined"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', \n",
    "                            target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add channel dimension for image\n",
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add batch dimension for image\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    print('Dog')\n",
    "else:\n",
    "    print('Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrevanth3.9",
   "language": "python",
   "name": "pyrevanth3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
